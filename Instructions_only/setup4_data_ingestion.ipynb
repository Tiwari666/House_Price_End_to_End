{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42169064",
   "metadata": {},
   "source": [
    "# DATA LOAD\n",
    "\n",
    "--create the conda envt : conda create -n lr_bankloan_env python=3.11 -y\n",
    "\n",
    "--Activate the Environment:  conda activate lr_bankloan_env\n",
    "\n",
    "-- Install Required Libraries: \n",
    "\n",
    "pip install pandas numpy seaborn matplotlib scikit-learn xgboost catboost flask ipykernel\n",
    "\n",
    "\n",
    "--Register Kernel for VS Code & Jupyter:\n",
    "\n",
    "python -m ipykernel install --user --name=lr_bankloan_env --display-name \"Python (lr_bankloan_env)\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d1774f",
   "metadata": {},
   "source": [
    "# ‚úÖ Goal of data_ingestion.py:\n",
    "\n",
    "\n",
    "\n",
    "Read raw data (CSV)\n",
    "\n",
    "Save it as-is (optional)\n",
    "\n",
    "Split into train & test sets\n",
    "\n",
    "Save the train/test data in the artifacts/ folder\n",
    "\n",
    "Return the file paths for further steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df0eba0",
   "metadata": {},
   "source": [
    "# Connected Modules Used in This File:\n",
    "\n",
    "| **Module**                           | **Purpose**                      |\n",
    "| ------------------------------------ | -------------------------------- |\n",
    "| `pandas`                             | Load the CSV file as a DataFrame |\n",
    "| `train_test_split` from `sklearn`    | Split data into training/testing |\n",
    "| `os`, `sys`                          | Handle file paths and exceptions |\n",
    "| `CustomException`, `logging`         | Log and handle errors cleanly    |\n",
    "| `DataTransformation`, `ModelTrainer` | Trigger next pipeline steps      |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1f852d",
   "metadata": {},
   "source": [
    "# What you expect after running the data_ingestion.py file?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3492bdec",
   "metadata": {},
   "source": [
    "## ‚úÖ When You Run `data_ingestion.py`, It will:\n",
    "\n",
    "- Read your raw data from this file:\n",
    "\n",
    "```bash\n",
    "notebook/data/loan_data.csv\n",
    "\n",
    "Create the artifacts/ folder (if it doesn‚Äôt already exist)\n",
    "\n",
    "Save 3 output files inside artifacts/:\n",
    "\n",
    "| üìÅ Location | üìÑ File Name | üìÑ Content Description                      |\n",
    "| ----------- | ------------ | ------------------------------------------- |\n",
    "| artifacts/  | data.csv     | The full original raw dataset (as-is)       |\n",
    "| artifacts/  | train.csv    | 80% of the data used for training           |\n",
    "| artifacts/  | test.csv     | 20% of the data used for testing/validation |\n",
    "\n",
    "\n",
    "Final Output Folder After Running data_ingestion.py:\n",
    "\n",
    "artifacts/\n",
    "‚îú‚îÄ‚îÄ data.csv      ‚Üê full raw data\n",
    "‚îú‚îÄ‚îÄ train.csv     ‚Üê training set (80%)\n",
    "‚îî‚îÄ‚îÄ test.csv      ‚Üê test set (20%)\n",
    "\n",
    "Summary:\n",
    "You do not need to manually create the artifacts/ folder.\n",
    "‚úÖ It will be created automatically, and all 3 files above will be saved inside.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e4d69bf",
   "metadata": {},
   "source": [
    "# Short cut for commmenting and uncommenting :\n",
    "\n",
    "Ctrl + /   ‚Üí Comments or uncomments them\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d48a0fb",
   "metadata": {},
   "source": [
    "# First time just run the following code:\n",
    "\n",
    "\n",
    "import os\n",
    "import sys\n",
    "#  treat the project root (LR_BankLoan) as the root module ‚Äî so from src.exception will now work.\n",
    "sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..')))\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from dataclasses import dataclass\n",
    "\n",
    "from src.exception import CustomException\n",
    "from src.logger import logging\n",
    "\n",
    "# üî¥ Future steps (commented for now)\n",
    "# from src.components.data_transformation import DataTransformation\n",
    "# from src.components.data_transformation import DataTransformationConfig\n",
    "# from src.components.model_trainer import ModelTrainer\n",
    "# from src.components.model_trainer import ModelTrainerConfig\n",
    "\n",
    "# Step 1: Define where to save files\n",
    "@dataclass\n",
    "class DataIngestionConfig:\n",
    "    train_data_path: str = os.path.join('artifacts', \"train.csv\")\n",
    "    test_data_path: str = os.path.join('artifacts', \"test.csv\")\n",
    "    raw_data_path: str = os.path.join('artifacts', \"data.csv\")\n",
    "\n",
    "# Step 2: Create class for data ingestion\n",
    "class DataIngestion:\n",
    "    def __init__(self):\n",
    "        self.ingestion_config = DataIngestionConfig()\n",
    "\n",
    "    # Step 3: Define ingestion process\n",
    "    def initiate_data_ingestion(self):\n",
    "        logging.info(\"Data Ingestion started\")\n",
    "        try:\n",
    "            # ‚úÖ Use your actual dataset\n",
    "            df = pd.read_csv('notebook/data/raw/loan_data.csv')\n",
    "            logging.info(\"Read the dataset as pandas DataFrame\")\n",
    "\n",
    "            # Create output folder if it doesn't exist\n",
    "            os.makedirs(os.path.dirname(self.ingestion_config.train_data_path), exist_ok=True)\n",
    "\n",
    "            # Save raw data\n",
    "            df.to_csv(self.ingestion_config.raw_data_path, index=False, header=True)\n",
    "            logging.info(\"Raw data saved\")\n",
    "\n",
    "            # Split into train and test\n",
    "            train_set, test_set = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "            # Save train and test sets\n",
    "            train_set.to_csv(self.ingestion_config.train_data_path, index=False, header=True)\n",
    "            test_set.to_csv(self.ingestion_config.test_data_path, index=False, header=True)\n",
    "\n",
    "            logging.info(\"Train and test data saved\")\n",
    "\n",
    "            return (\n",
    "                self.ingestion_config.train_data_path,\n",
    "                self.ingestion_config.test_data_path,\n",
    "                self.ingestion_config.raw_data_path\n",
    "            )\n",
    "\n",
    "        except Exception as e:\n",
    "            raise CustomException(e, sys) from e\n",
    "\n",
    "# Step 4: Run and test only data ingestion for now\n",
    "if __name__ == \"__main__\":\n",
    "    data_ingestion = DataIngestion()\n",
    "    train_data_path, test_data_path, raw_data_path = data_ingestion.initiate_data_ingestion()\n",
    "\n",
    "    # üîí Future steps (enable after building next modules)\n",
    "    # data_transformation = DataTransformation()\n",
    "    # data_transformation_config = DataTransformationConfig()\n",
    "    # model_trainer = ModelTrainer()\n",
    "    # model_trainer_config = ModelTrainerConfig()\n",
    "    # train_arr, test_arr, _ = data_transformation.initiate_data_transformation(train_data_path, test_data_path)\n",
    "    # print(model_trainer.initiate_model_trainer(train_arr, test_arr))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8d03b3",
   "metadata": {},
   "source": [
    "# second time: Run the following code once you created the data_transforamtion.py module:\n",
    "\n",
    "\n",
    "import os\n",
    "import sys\n",
    "#  treat the project root (LR_BankLoan) as the root module ‚Äî so from src.exception will now work.\n",
    "sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..')))\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from dataclasses import dataclass\n",
    "\n",
    "from src.exception import CustomException\n",
    "from src.logger import logging\n",
    "\n",
    "from src.components.data_transformation import DataTransformation\n",
    "from src.components.data_transformation import DataTransformationConfig\n",
    "\n",
    "from src.components.model_trainer import ModelTrainer\n",
    "from src.components.model_trainer import ModelTrainerConfig\n",
    "\n",
    "# Step 1: Define where to save files (using @dataclass)\n",
    "@dataclass\n",
    "class DataIngestionConfig:\n",
    "    train_data_path: str = os.path.join('artifacts', \"train.csv\")\n",
    "    test_data_path: str = os.path.join('artifacts', \"test.csv\")\n",
    "    raw_data_path: str = os.path.join('artifacts', \"data.csv\")\n",
    "\n",
    "# Step 2: Create a class for data ingestion\n",
    "class DataIngestion:\n",
    "    def __init__(self):\n",
    "        self.ingestion_config = DataIngestionConfig()\n",
    "\n",
    "    # Step 3: Define the ingestion process    \n",
    "    def initiate_data_ingestion(self):\n",
    "        logging.info(\"Data Ingestion started\")\n",
    "        try:\n",
    "            # use the actual data file: loan_data.csv\n",
    "            df = pd.read_csv('notebook/data/raw/loan_data.csv')\n",
    "\n",
    "            logging.info(\"Read the Dataset as pandas dataframe\")\n",
    "\n",
    "            # Create directories/folders if they don't exist\n",
    "            os.makedirs(os.path.dirname(self.ingestion_config.train_data_path), exist_ok=True)\n",
    "\n",
    "            # Save the raw data\n",
    "            df.to_csv(self.ingestion_config.raw_data_path, index=False, header=True)\n",
    "            logging.info(\"Raw data saved\")\n",
    "\n",
    "            # Split the data into train and test sets\n",
    "            train_set, test_set = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "            # Save the train and test sets\n",
    "            train_set.to_csv(self.ingestion_config.train_data_path, index=False, header=True)\n",
    "            test_set.to_csv(self.ingestion_config.test_data_path, index=False, header=True)\n",
    "\n",
    "            logging.info(\"Train and test data saved\")\n",
    "\n",
    "            return (\n",
    "                self.ingestion_config.train_data_path,\n",
    "                self.ingestion_config.test_data_path,\n",
    "                self.ingestion_config.raw_data_path\n",
    "            )\n",
    "\n",
    "        except Exception as e:\n",
    "            raise CustomException(e, sys) from e\n",
    "\n",
    "# Step 4: Test the DataIngestion class / Run this step and connect next steps\n",
    "if __name__ == \"__main__\":\n",
    "    data_ingestion = DataIngestion()\n",
    "    train_data_path, test_data_path, raw_data_path = data_ingestion.initiate_data_ingestion()\n",
    "\n",
    "    # Step 5: Call the DataTransformation class\n",
    "    data_transformation = DataTransformation()\n",
    "    data_transformation_config = DataTransformationConfig()\n",
    "\n",
    "    # Step 6: Call the ModelTrainer class\n",
    "    model_trainer = ModelTrainer()\n",
    "    model_trainer_config = ModelTrainerConfig()\n",
    "\n",
    "    # Call the data transformation and model trainer methods to Make sure model receives transformed data\n",
    "    train_arr, test_arr, _ = data_transformation.initiate_data_transformation(train_data_path, test_data_path)\n",
    "\n",
    "    print(model_trainer.initiate_model_trainer(train_arr, test_arr))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f3e73e",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (lr_bankloan_env)",
   "language": "python",
   "name": "lr_bankloan_env"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
