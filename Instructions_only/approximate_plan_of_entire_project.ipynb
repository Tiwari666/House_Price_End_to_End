{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "209fd13b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d6d48be7",
   "metadata": {},
   "source": [
    "# Step-by-Step Plan to Modularize & Deploy the ML Pipeline\n",
    "\n",
    "## Model Development Phase\n",
    "âœ”ï¸ EDA (`01_EDA_BankLoan.ipynb`)  \n",
    "âœ”ï¸ Preprocessing (`02_Preprocessing.ipynb`)  \n",
    "âœ”ï¸ Model Training (`03_ModelTraining.ipynb`)  \n",
    "âœ”ï¸ Cross-Validation (RandomizedSearchCV)  \n",
    "âœ”ï¸ Saved model: `model/best_model.pkl`\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ§© Code Modularization:\n",
    "\n",
    "### ğŸ”· Step 1: `data_ingestion.py`\n",
    "- Read raw CSV  \n",
    "- `load_data(path: str) â†’ pd.DataFrame`\n",
    "\n",
    "### ğŸ”· Step 2: `data_transformation.py`\n",
    "- Preprocessing steps  \n",
    "- Returns: `X_train`, `X_test`, `y_train`, `y_test`\n",
    "\n",
    "### ğŸ”· Step 3: `model_trainer.py`\n",
    "- Train & tune model  \n",
    "- Save best model\n",
    "\n",
    "### ğŸ”· Step 4: `utils.py`\n",
    "- `save_object()`, `load_object()`, `evaluate_models()`\n",
    "\n",
    "### ğŸ”· Step 5: `exception.py` & `logger.py`\n",
    "- âœ…  (for error handling and logging)\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ”— Pipeline Integration:\n",
    "\n",
    "### ğŸ”· Step 6: `pipeline/train_pipeline.py`\n",
    "- Combine: Load â†’ Transform â†’ Train â†’ Save\n",
    "\n",
    "### ğŸ”· Step 7: `pipeline/predict_pipeline.py`\n",
    "- Load `best_model.pkl`  \n",
    "- Predict on new data\n",
    "\n",
    "### ğŸ”· Step 8: `requirements.txt` & `setup.py`\n",
    "- âœ…  for reproducibility\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“Š  Evaluation\n",
    "\n",
    "### ğŸ”· Step 9: `model_evaluation.ipynb`\n",
    "- Compare results before & after tuning visually\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸŒ Deployment\n",
    "\n",
    "### ğŸ”· Step 10: Flask App Deployment (Local)\n",
    "- `app.py`: Flask app for prediction  \n",
    "- `templates/index.html`: User input form  \n",
    "\n",
    "**Run locally:**\n",
    "```bash\n",
    "python app.py\n",
    "\n",
    "\n",
    "### ğŸ”· Step 11: Dockerization\n",
    "- `app.py`: Flask app for prediction  \n",
    "- `templates/index.html`: User input form  \n",
    "\n",
    "**Run locally:**\n",
    "```bash\n",
    "python app.py\n",
    "\n",
    "\n",
    "## ğŸ³ Step 11: Dockerization Phase  \n",
    "ğŸ“¦ Package the entire app with its dependencies so it can run anywhere.\n",
    "\n",
    "- Create a `Dockerfile`\n",
    "- Add a `.dockerignore`\n",
    "- Build the Docker image\n",
    "- Run the image locally\n",
    "\n",
    "âœ… The ML app is now a self-contained deployable unit.\n",
    "\n",
    "\n",
    "## â˜ï¸ Step 12: Cloud Deployment Phase  \n",
    "ğŸš€ Deploy the Dockerized app to the cloud for public access.\n",
    "\n",
    "### âœ… Option A: Render\n",
    "- Push project to GitHub  \n",
    "- Add `Procfile`  \n",
    "- Connect GitHub repo on [render.com](https://render.com)\n",
    "\n",
    "### âœ… Option B: Heroku\n",
    "- Add `Procfile`, `runtime.txt`\n",
    "```bash\n",
    "heroku login\n",
    "heroku create your-app-name\n",
    "git push heroku main\n",
    "\n",
    "\n",
    "### âœ… Option C: AWS / GCP / Azure  \n",
    "Use Docker image and deploy via:\n",
    "\n",
    "- **AWS**: EC2 or ECS  \n",
    "- **GCP**: Cloud Run  \n",
    "- **Azure**: App Service\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a060c43",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "56969f12",
   "metadata": {},
   "source": [
    "| Module                            | Class / Function               | Description                                        |\n",
    "|----------------------------------|-------------------------------|----------------------------------------------------|\n",
    "| `src/utils.py`                   | `save_object()`               | Saves Python objects (models, preprocessors)       |\n",
    "|                                  | `load_object()`               | Loads saved `.pkl` object                          |\n",
    "|                                  | `evaluate_models()`           | Evaluates models with tuning + metrics             |\n",
    "|                                  | â®• Used in:                    | `model_trainer.py`, `predict_pipeline.py`          |\n",
    "|----------------------------------|-------------------------------|----------------------------------------------------|\n",
    "| `src/components/data_ingestion.py` | `DataIngestion`              | Loads raw data, splits into train/test             |\n",
    "|                                  | `initiate_data_ingestion()`   | Executes data ingestion logic                      |\n",
    "|                                  | â®• Used in:                    | `train_pipeline.py`                                |\n",
    "|----------------------------------|-------------------------------|----------------------------------------------------|\n",
    "| `src/components/data_transformation.py` | `DataTransformation`     | Transforms data (cleaning, encoding, scaling)      |\n",
    "|                                  | `get_data_transformer_object()` | Builds preprocessing pipeline                    |\n",
    "|                                  | `initiate_data_transformation()`| Applies transformations to train/test             |\n",
    "|                                  | â®• Used in:                    | `train_pipeline.py`                                |\n",
    "|----------------------------------|-------------------------------|----------------------------------------------------|\n",
    "| `src/components/model_trainer.py` | `ModelTrainer`               | Trains and saves the best regression model         |\n",
    "|                                  | `initiate_model_trainer()`    | Runs training + tuning for all models              |\n",
    "|                                  | â®• Uses:                       | `evaluate_models()` from `utils.py`                |\n",
    "|                                  | â®• Saves to:                   | `artifacts/best_model.pkl`                         |\n",
    "|                                  | â®• Used in:                    | `train_pipeline.py`                                |\n",
    "|----------------------------------|-------------------------------|----------------------------------------------------|\n",
    "| `src/pipeline/train_pipeline.py` | *Main Script*                 | Orchestrates full training pipeline                |\n",
    "|                                  | â®• Calls:                      | `DataIngestion`, `DataTransformation`, `ModelTrainer` |\n",
    "|----------------------------------|-------------------------------|----------------------------------------------------|\n",
    "| `src/pipeline/predict_pipeline.py` | `PredictPipeline`           | Loads model and preprocessor to make prediction    |\n",
    "|                                  | `predict()`                   | Predicts interest rate based on input              |\n",
    "|                                  | `CustomData`                  | Builds DataFrame from form/manual input            |\n",
    "|                                  | â®• Uses:                       | `load_object()` from `utils.py`                    |\n",
    "|                                  | â®• Loads from:                 | `artifacts/best_model.pkl`, `preprocessor.pkl`     |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05fd771",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
